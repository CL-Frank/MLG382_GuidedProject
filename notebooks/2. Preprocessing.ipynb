{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0974493b",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e187ee",
   "metadata": {},
   "source": [
    "## Getting The System Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd0374fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import scipy.stats as stats\n",
    "# import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34dd433",
   "metadata": {},
   "source": [
    "## Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70a1d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for the dataset\n",
    "file_path = \"../data/Student_performance_data .csv\" \n",
    "\n",
    "# Checking of the file\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"The file '{file_path}' was not found in {os.getcwd()}. \"\n",
    "        f\"Please ensure the file is in the correct directory or provide the correct path. \"\n",
    "        f\"Available files in 'data': {os.listdir('data')}\"\n",
    "    )\n",
    "    \n",
    "    # Loading the dataset\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Failed to load CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b03d8b",
   "metadata": {},
   "source": [
    "## 1. Missing Value and Oulier Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19f8f2",
   "metadata": {},
   "source": [
    "### *i.* Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cd7b56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      " StudentID            0\n",
      "Age                  0\n",
      "Gender               0\n",
      "Ethnicity            0\n",
      "ParentalEducation    0\n",
      "StudyTimeWeekly      0\n",
      "Absences             0\n",
      "Tutoring             0\n",
      "ParentalSupport      0\n",
      "Extracurricular      0\n",
      "Sports               0\n",
      "Music                0\n",
      "Volunteering         0\n",
      "GPA                  0\n",
      "GradeClass           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for any missing values of the dataset\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"\\nMissing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5aeab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the numerical columns are numeric\n",
    "numerical_cols = ['StudyTimeWeekly', 'Absences', 'GPA']\n",
    "for col in numerical_cols:\n",
    "    try:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not convert {col} to numeric: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4341042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values (if there is any)\n",
    "for col in numerical_cols:\n",
    "    try:\n",
    "        if data[col].isnull().any():\n",
    "            median_value = data[col].median()\n",
    "            data[col] = data[col].fillna(median_value)\n",
    "            print(f\"Imputed missing values in {col} with median: {median_value}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error imputing {col}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2538ad",
   "metadata": {},
   "source": [
    "### *i.* Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "680c6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check for any missing values in categorical columns, impute with mode\n",
    "categorical_cols = ['Gender', 'Ethnicity', 'ParentalEducation', 'Tutoring', 'ParentalSupport', \n",
    "                    'Extracurricular', 'Sports', 'Music', 'Volunteering']\n",
    "for col in categorical_cols:\n",
    "    try:\n",
    "        if data[col].isnull().any():\n",
    "            mode_value = data[col].mode()[0]\n",
    "            data[col] = data[col].fillna(mode_value)\n",
    "            print(f\"Imputed missing values in {col} with mode: {mode_value}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error imputing {col}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ae07f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection and treatment using Z-score\n",
    "def detect_outliers_zscore(df, column, threshold=3):\n",
    "    try:\n",
    "        # Ensure column is numeric and drop NaN values for Z-score calculation\n",
    "        col_data = pd.to_numeric(df[column], errors='coerce').dropna()\n",
    "        if col_data.empty:\n",
    "            print(f\"No valid data in {column} for outlier detection\")\n",
    "            return pd.DataFrame()\n",
    "        z_scores = np.abs(stats.zscore(col_data))\n",
    "        outliers = df.loc[col_data.index][z_scores > threshold]\n",
    "        return outliers\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting outliers in {column}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e07a4e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No outliers detected in StudyTimeWeekly\n",
      "\n",
      "No outliers detected in Absences\n",
      "\n",
      "No outliers detected in GPA\n",
      "Capped outliers in StudyTimeWeekly at 1st (0.19036748663715453) and 99th (19.720476474805494) percentiles\n",
      "Capped outliers in Absences at 1st (0.0) and 99th (29.0) percentiles\n",
      "Capped outliers in GPA at 1st (0.11152134489227275) and 99th (3.748510617060825) percentiles\n",
      "\n",
      "Summary of StudyTimeWeekly after capping:\n",
      " count    2392.000000\n",
      "mean        9.771592\n",
      "std         5.648582\n",
      "min         0.190367\n",
      "25%         5.043079\n",
      "50%         9.705363\n",
      "75%        14.408410\n",
      "max        19.720476\n",
      "Name: StudyTimeWeekly, dtype: float64\n",
      "\n",
      "Summary of Absences after capping:\n",
      " count    2392.000000\n",
      "mean       14.541388\n",
      "std         8.467417\n",
      "min         0.000000\n",
      "25%         7.000000\n",
      "50%        15.000000\n",
      "75%        22.000000\n",
      "max        29.000000\n",
      "Name: Absences, dtype: float64\n",
      "\n",
      "Summary of GPA after capping:\n",
      " count    2392.000000\n",
      "mean        1.905612\n",
      "std         0.909947\n",
      "min         0.111521\n",
      "25%         1.174803\n",
      "50%         1.893393\n",
      "75%         2.622216\n",
      "max         3.748511\n",
      "Name: GPA, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Numerical columns to check for outliers\n",
    "for col in numerical_cols:\n",
    "    try:\n",
    "        outliers = detect_outliers_zscore(data, col)\n",
    "        if not outliers.empty:\n",
    "            print(f\"\\nOutliers in {col}:\\n\", outliers[[col]])\n",
    "        else:\n",
    "            print(f\"\\nNo outliers detected in {col}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing outliers for {col}: {e}\")\n",
    "\n",
    "# Capping the outliers at the 1st and 99th percentiles\n",
    "for col in numerical_cols:\n",
    "    try:\n",
    "        lower_bound = data[col].quantile(0.01)\n",
    "        upper_bound = data[col].quantile(0.99)\n",
    "        if not pd.isna(lower_bound) and not pd.isna(upper_bound):\n",
    "            data[col] = data[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "            print(f\"Capped outliers in {col} at 1st ({lower_bound}) and 99th ({upper_bound}) percentiles\")\n",
    "        else:\n",
    "            print(f\"Skipping outlier capping for {col} due to invalid quantiles\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error capping outliers in {col}: {e}\")\n",
    "\n",
    "# Verifying for the outlier treatment\n",
    "for col in numerical_cols:\n",
    "    try:\n",
    "        print(f\"\\nSummary of {col} after capping:\\n\", data[col].describe())\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing {col}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ac782",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "235454b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns of the dataset that are unnecessary\n",
    "data.drop(['StudentID','GPA'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e50af238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new features\n",
    "data['StudyTimePerAbsence'] = data['StudyTimeWeekly'] / (data['Absences'] + 1)\n",
    "\n",
    "data['TotalExtracurricular'] = data[['Extracurricular', 'Sports', 'Music', 'Volunteering']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2b71999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StudyTimeWeekly to be divided into categories\n",
    "bins = [0, 5, 10, 15, 20]\n",
    "labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "data['StudyTimeCategory'] = pd.cut(data['StudyTimeWeekly'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "categorical_cols_to_encode = ['Ethnicity', 'ParentalEducation', 'StudyTimeCategory']\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols_to_encode, drop_first=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_cols_to_scale = ['Age','StudyTimeWeekly', 'Absences', 'StudyTimePerAbsence', 'TotalExtracurricular']\n",
    "scaler.fit_transform(data_encoded[numerical_cols_to_scale])\n",
    "data_encoded[numerical_cols_to_scale] = scaler.fit_transform(data_encoded[numerical_cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e3bc985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Feature Set Columns:\n",
      " Index(['Age', 'Gender', 'StudyTimeWeekly', 'Absences', 'Tutoring',\n",
      "       'ParentalSupport', 'Extracurricular', 'Sports', 'Music', 'Volunteering',\n",
      "       'GradeClass', 'StudyTimePerAbsence', 'TotalExtracurricular',\n",
      "       'Ethnicity_1', 'Ethnicity_2', 'Ethnicity_3', 'ParentalEducation_1',\n",
      "       'ParentalEducation_2', 'ParentalEducation_3', 'ParentalEducation_4',\n",
      "       'StudyTimeCategory_Moderate', 'StudyTimeCategory_High',\n",
      "       'StudyTimeCategory_Very High'],\n",
      "      dtype='object')\n",
      "\n",
      "First 5 rows of processed dataset:\n",
      "         Age  Gender  StudyTimeWeekly  Absences  Tutoring  ParentalSupport  \\\n",
      "0  0.472919       1         1.761675 -0.890822         1                2   \n",
      "1  1.362944       0         0.998187 -1.717694         0                1   \n",
      "2 -1.307132       0        -0.984705  1.353542         0                2   \n",
      "3  0.472919       1         0.045550 -0.063951         0                3   \n",
      "4  0.472919       1        -0.902910  0.290422         1                3   \n",
      "\n",
      "   Extracurricular  Sports  Music  Volunteering  ...  Ethnicity_1  \\\n",
      "0                0       0      1             0  ...        False   \n",
      "1                0       0      0             0  ...        False   \n",
      "2                0       0      0             0  ...        False   \n",
      "3                1       0      0             0  ...        False   \n",
      "4                0       0      0             0  ...        False   \n",
      "\n",
      "   Ethnicity_2  Ethnicity_3  ParentalEducation_1  ParentalEducation_2  \\\n",
      "0        False        False                False                 True   \n",
      "1        False        False                 True                False   \n",
      "2         True        False                False                False   \n",
      "3        False        False                False                False   \n",
      "4        False        False                False                 True   \n",
      "\n",
      "   ParentalEducation_3  ParentalEducation_4  StudyTimeCategory_Moderate  \\\n",
      "0                False                False                       False   \n",
      "1                False                False                       False   \n",
      "2                 True                False                       False   \n",
      "3                 True                False                       False   \n",
      "4                False                False                       False   \n",
      "\n",
      "   StudyTimeCategory_High  StudyTimeCategory_Very High  \n",
      "0                   False                         True  \n",
      "1                   False                         True  \n",
      "2                   False                        False  \n",
      "3                    True                        False  \n",
      "4                   False                        False  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For the final dataset to display\n",
    "print(\"\\nFinal Feature Set Columns:\\n\", data_encoded.columns)\n",
    "print(\"\\nFirst 5 rows of processed dataset:\\n\", data_encoded.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9f907",
   "metadata": {},
   "source": [
    "## 3. Saving The Newly Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4001f1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed dataset saved as 'Processed_Student_Performance.csv'\n"
     ]
    }
   ],
   "source": [
    "# This saves the new processed dataset\n",
    "data_encoded.to_csv(\"../data/Processed_Student_Performance.csv\", index=False)\n",
    "print(\"\\nProcessed dataset saved as 'Processed_Student_Performance.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9d72825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the new features and scaler\n",
    "with open(\"../artifacts/features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_encoded.columns, f)\n",
    "\n",
    "with open(\"../artifacts/scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
